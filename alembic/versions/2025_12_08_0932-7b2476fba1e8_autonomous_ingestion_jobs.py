"""autonomous ingestion jobs

Revision ID: 7b2476fba1e8
Revises: b06b792da046
Create Date: 2025-12-08 09:32:42.508280+00:00

"""

from typing import Sequence, Union

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "7b2476fba1e8"
down_revision: Union[str, Sequence[str], None] = "b06b792da046"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "data_sources",
        sa.Column("uid", sa.String(length=36), nullable=False),
        sa.Column(
            "name",
            sa.String(length=50),
            nullable=False,
            comment="sentinel-2-l2a, landsat-8, modis",
        ),
        sa.Column(
            "revisit_frequency_days",
            sa.Integer(),
            nullable=False,
            comment="Satellite revisit frequency (5 days for Sentinel-2)",
        ),
        sa.Column(
            "availability_lag_days",
            sa.Integer(),
            nullable=False,
            comment="Processing delay (1-2 days for Sentinel Hub)",
        ),
        sa.Column(
            "sync_frequency_days",
            sa.Integer(),
            nullable=False,
            comment="How often to run ingestion (7 days default)",
        ),
        sa.Column("api_endpoint", sa.String(length=255), nullable=False),
        sa.Column("max_cloud_coverage", sa.Integer(), nullable=False),
        sa.Column("is_active", sa.Boolean(), nullable=False),
        sa.PrimaryKeyConstraint("uid"),
        sa.UniqueConstraint("name"),
    )
    op.create_table(
        "ingestion_jobs",
        sa.Column("uid", sa.String(length=60), nullable=False),
        sa.Column("parcel_id", sa.String(length=60), nullable=False),
        sa.Column(
            "requested_start_date",
            sa.Date(),
            nullable=False,
            comment="Start of requested window",
        ),
        sa.Column(
            "requested_end_date",
            sa.Date(),
            nullable=False,
            comment="End of requested window",
        ),
        sa.Column(
            "actual_start_date",
            sa.Date(),
            nullable=True,
            comment="Earliest acquisition date retrieved",
        ),
        sa.Column(
            "actual_end_date",
            sa.Date(),
            nullable=True,
            comment="Latest acquisition date retrieved",
        ),
        sa.Column(
            "status",
            sa.String(length=20),
            nullable=False,
            comment="pending, running, completed, partial, failed",
        ),
        sa.Column(
            "records_created",
            sa.Integer(),
            nullable=False,
            comment="Number of raster_stats records created",
        ),
        sa.Column(
            "records_skipped",
            sa.Integer(),
            nullable=False,
            comment="Number of records skipped (already exist)",
        ),
        sa.Column(
            "error_message",
            sa.Text(),
            nullable=True,
            comment="Error message if job failed",
        ),
        sa.Column(
            "retry_count",
            sa.Integer(),
            nullable=False,
            comment="Number of retry attempts",
        ),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column(
            "started_at",
            sa.DateTime(),
            nullable=True,
            comment="When job execution started",
        ),
        sa.Column(
            "completed_at",
            sa.DateTime(),
            nullable=True,
            comment="When job finished (success or failure)",
        ),
        sa.Column(
            "job_type",
            sa.String(length=20),
            nullable=False,
            comment="backfill, periodic, manual, retry",
        ),
        sa.Column("data_source_id", sa.String(length=36), nullable=False),
        sa.Column(
            "metric_type",
            sa.String(length=20),
            nullable=False,
            comment="Which index to compute",
        ),
        sa.Column(
            "execution_metadata",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
            comment="Full execution context, API responses, etc.",
        ),
        sa.ForeignKeyConstraint(
            ["data_source_id"],
            ["data_sources.uid"],
        ),
        sa.ForeignKeyConstraint(["parcel_id"], ["parcels.uid"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("uid"),
    )
    op.create_index(
        "idx_jobs_parcel_status",
        "ingestion_jobs",
        ["parcel_id", "status"],
        unique=False,
    )
    op.create_index(
        "idx_jobs_status_created",
        "ingestion_jobs",
        ["status", "created_at"],
        unique=False,
    )
    op.create_index(
        op.f("ix_ingestion_jobs_data_source_id"),
        "ingestion_jobs",
        ["data_source_id"],
        unique=False,
    )
    op.create_index(
        op.f("ix_ingestion_jobs_parcel_id"),
        "ingestion_jobs",
        ["parcel_id"],
        unique=False,
    )
    op.create_index(
        op.f("ix_ingestion_jobs_status"), "ingestion_jobs", ["status"], unique=False
    )
    op.add_column(
        "parcels",
        sa.Column(
            "last_data_synced_at",
            sa.DateTime(),
            nullable=True,
            comment="Timestamp of last successful data sync(any job)",
        ),
    )
    op.add_column(
        "parcels",
        sa.Column(
            "latest_acquisition_date",
            sa.Date(),
            nullable=True,
            comment="Most recent acquisition_date in raster_stats",
        ),
    )
    op.add_column(
        "parcels",
        sa.Column(
            "next_sync_scheduled_at",
            sa.DateTime(),
            nullable=True,
            comment="When to schedule next ingestion job",
        ),
    )
    op.add_column(
        "parcels", sa.Column("auto_sync_enabled", sa.Boolean(), nullable=True)
    )
    op.create_index(
        op.f("ix_parcels_next_sync_scheduled_at"),
        "parcels",
        ["next_sync_scheduled_at"],
        unique=False,
    )
    op.add_column(
        "raster_stats",
        sa.Column("data_source_id", sa.String(length=36), nullable=False),
    )
    op.alter_column(
        "raster_stats",
        "raw_metadata",
        existing_type=postgresql.JSONB(astext_type=sa.Text()),
        comment="Store full response for debugging",
        existing_comment="Store full Sentinel Hub response for debugging",
        existing_nullable=True,
    )
    op.create_index(
        op.f("ix_raster_stats_data_source_id"),
        "raster_stats",
        ["data_source_id"],
        unique=False,
    )
    op.create_foreign_key(
        None, "raster_stats", "data_sources", ["data_source_id"], ["uid"]
    )
    op.drop_column("raster_stats", "satellite_source")
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column(
        "raster_stats",
        sa.Column(
            "satellite_source",
            sa.VARCHAR(length=50),
            autoincrement=False,
            nullable=False,
            comment="sentinel-2-l2a, landsat-8",
        ),
    )
    op.drop_constraint(None, "raster_stats", type_="foreignkey")
    op.drop_index(op.f("ix_raster_stats_data_source_id"), table_name="raster_stats")
    op.alter_column(
        "raster_stats",
        "raw_metadata",
        existing_type=postgresql.JSONB(astext_type=sa.Text()),
        comment="Store full Sentinel Hub response for debugging",
        existing_comment="Store full response for debugging",
        existing_nullable=True,
    )
    op.drop_column("raster_stats", "data_source_id")
    op.drop_index(op.f("ix_parcels_next_sync_scheduled_at"), table_name="parcels")
    op.drop_column("parcels", "auto_sync_enabled")
    op.drop_column("parcels", "next_sync_scheduled_at")
    op.drop_column("parcels", "latest_acquisition_date")
    op.drop_column("parcels", "last_data_synced_at")
    op.drop_index(op.f("ix_ingestion_jobs_status"), table_name="ingestion_jobs")
    op.drop_index(op.f("ix_ingestion_jobs_parcel_id"), table_name="ingestion_jobs")
    op.drop_index(op.f("ix_ingestion_jobs_data_source_id"), table_name="ingestion_jobs")
    op.drop_index("idx_jobs_status_created", table_name="ingestion_jobs")
    op.drop_index("idx_jobs_parcel_status", table_name="ingestion_jobs")
    op.drop_table("ingestion_jobs")
    op.drop_table("data_sources")
    # ### end Alembic commands ###
