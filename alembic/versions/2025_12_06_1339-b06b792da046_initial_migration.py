"""initial migration

Revision ID: b06b792da046
Revises:
Create Date: 2025-12-06 13:39:54.694679+00:00

"""

from typing import Sequence, Union

import geoalchemy2
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "b06b792da046"
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "parcels",
        sa.Column("uid", sa.String(length=36), nullable=False),
        sa.Column("name", sa.String(length=255), nullable=False),
        sa.Column(
            "geometry",
            geoalchemy2.types.Geometry(
                geometry_type="POLYGON",
                srid=4326,
                dimension=2,
                from_text="ST_GeomFromEWKT",
                name="geometry",
                nullable=False,
            ),
            nullable=False,
        ),
        sa.Column("area_hectares", sa.Numeric(precision=10, scale=4), nullable=True),
        sa.Column("soil_type", sa.String(length=100), nullable=True),
        sa.Column("crop_type", sa.String(length=100), nullable=True),
        sa.Column(
            "irrigation_type",
            sa.String(length=50),
            nullable=True,
            comment="rainfed, irrigated, mixed",
        ),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.Column(
            "is_active",
            sa.Boolean(),
            nullable=False,
            comment="Whether to actively monitor this parcel",
        ),
        sa.PrimaryKeyConstraint("uid"),
    )
    # op.create_index(
    #     "idx_parcels_geometry",
    #     "parcels",
    #     ["geometry"],
    #     unique=False,
    #     postgresql_using="gist",
    # ) already exists!
    op.create_table(
        "alerts",
        sa.Column("uid", sa.String(length=36), nullable=False),
        sa.Column("parcel_id", sa.String(length=36), nullable=False),
        sa.Column(
            "alert_type",
            sa.String(length=100),
            nullable=False,
            comment="drought_risk, vegetation_decline, anomaly, pest_stress, etc.",
        ),
        sa.Column(
            "severity",
            sa.String(length=20),
            nullable=False,
            comment="low, medium, high, critical",
        ),
        sa.Column("message", sa.Text(), nullable=False),
        sa.Column("detected_at", sa.DateTime(), nullable=False),
        sa.Column(
            "status",
            sa.String(length=20),
            nullable=False,
            comment="active, resolved, dismissed",
        ),
        sa.Column("resolved_at", sa.DateTime(), nullable=True),
        sa.Column(
            "alerts_data",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
            comment="Store alert-specific data like thresholds, values, etc.",
        ),
        sa.ForeignKeyConstraint(["parcel_id"], ["parcels.uid"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("uid"),
    )
    op.create_index(
        "idx_alerts_parcel_status", "alerts", ["parcel_id", "status"], unique=False
    )
    op.create_index("idx_alerts_status", "alerts", ["status"], unique=False)
    op.create_index(
        op.f("ix_alerts_detected_at"), "alerts", ["detected_at"], unique=False
    )
    op.create_index(op.f("ix_alerts_parcel_id"), "alerts", ["parcel_id"], unique=False)
    op.create_table(
        "raster_stats",
        sa.Column("uid", sa.String(length=36), nullable=False),
        sa.Column("parcel_id", sa.String(length=36), nullable=False),
        sa.Column("acquisition_date", sa.Date(), nullable=False),
        sa.Column(
            "satellite_source",
            sa.String(length=50),
            nullable=False,
            comment="sentinel-2-l2a, landsat-8",
        ),
        sa.Column(
            "metric_type",
            sa.String(length=50),
            nullable=False,
            comment="NDVI, EVI, NDMI, SAVI, LAI",
        ),
        sa.Column("mean_value", sa.Numeric(precision=10, scale=6), nullable=False),
        sa.Column("min_value", sa.Numeric(precision=10, scale=6), nullable=False),
        sa.Column("max_value", sa.Numeric(precision=10, scale=6), nullable=False),
        sa.Column("std_dev", sa.Numeric(precision=10, scale=6), nullable=True),
        sa.Column(
            "cloud_cover_percent",
            sa.Numeric(precision=5, scale=2),
            nullable=True,
            comment="Percentage of cloud cover in the image",
        ),
        sa.Column(
            "pixel_count",
            sa.Integer(),
            nullable=True,
            comment="Number of valid pixels processed",
        ),
        sa.Column("processed_at", sa.DateTime(), nullable=False),
        sa.Column(
            "raw_metadata",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
            comment="Store full Sentinel Hub response for debugging",
        ),
        sa.ForeignKeyConstraint(["parcel_id"], ["parcels.uid"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("uid"),
        sa.UniqueConstraint(
            "parcel_id", "acquisition_date", "metric_type", name="uq_parcel_date_index"
        ),
    )
    op.create_index(
        "idx_raster_parcel_date",
        "raster_stats",
        ["parcel_id", "acquisition_date"],
        unique=False,
    )
    op.create_index(
        op.f("ix_raster_stats_acquisition_date"),
        "raster_stats",
        ["acquisition_date"],
        unique=False,
    )
    op.create_index(
        op.f("ix_raster_stats_parcel_id"), "raster_stats", ["parcel_id"], unique=False
    )
    op.create_table(
        "time_series",
        sa.Column("uid", sa.String(length=36), nullable=False),
        sa.Column("parcel_id", sa.String(length=36), nullable=False),
        sa.Column(
            "metric_type",
            sa.String(length=50),
            nullable=False,
            comment="ndvi_avg, ndmi_avg, rainfall_total, temperature_avg, etc.",
        ),
        sa.Column(
            "time_period",
            sa.String(length=20),
            nullable=False,
            comment="daily, weekly, monthly",
        ),
        sa.Column("start_date", sa.Date(), nullable=False),
        sa.Column("end_date", sa.Date(), nullable=False),
        sa.Column("value", sa.Numeric(precision=10, scale=6), nullable=False),
        sa.Column(
            "change_from_previous",
            sa.Numeric(precision=10, scale=6),
            nullable=True,
            comment="Percentage change from previous period",
        ),
        sa.Column(
            "is_anomaly",
            sa.Boolean(),
            nullable=False,
            comment="Flagged as statistically unusual",
        ),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(["parcel_id"], ["parcels.uid"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("uid"),
        sa.UniqueConstraint(
            "parcel_id",
            "metric_type",
            "time_period",
            "start_date",
            name="uq_timeseries_parcel_metric_period_date",
        ),
    )
    op.create_index(
        "idx_timeseries_parcel_dates",
        "time_series",
        ["parcel_id", "start_date", "end_date"],
        unique=False,
    )
    op.create_index(
        op.f("ix_time_series_end_date"), "time_series", ["end_date"], unique=False
    )
    op.create_index(
        op.f("ix_time_series_parcel_id"), "time_series", ["parcel_id"], unique=False
    )
    op.create_index(
        op.f("ix_time_series_start_date"), "time_series", ["start_date"], unique=False
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f("ix_time_series_start_date"), table_name="time_series")
    op.drop_index(op.f("ix_time_series_parcel_id"), table_name="time_series")
    op.drop_index(op.f("ix_time_series_end_date"), table_name="time_series")
    op.drop_index("idx_timeseries_parcel_dates", table_name="time_series")
    op.drop_table("time_series")
    op.drop_index(op.f("ix_raster_stats_parcel_id"), table_name="raster_stats")
    op.drop_index(op.f("ix_raster_stats_acquisition_date"), table_name="raster_stats")
    op.drop_index("idx_raster_parcel_date", table_name="raster_stats")
    op.drop_table("raster_stats")
    op.drop_index(op.f("ix_alerts_parcel_id"), table_name="alerts")
    op.drop_index(op.f("ix_alerts_detected_at"), table_name="alerts")
    op.drop_index("idx_alerts_status", table_name="alerts")
    op.drop_index("idx_alerts_parcel_status", table_name="alerts")
    op.drop_table("alerts")
    op.drop_index("idx_parcels_geometry", table_name="parcels", postgresql_using="gist")
    op.drop_table("parcels")
    # ### end Alembic commands ###
